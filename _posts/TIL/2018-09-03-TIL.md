---
layout: post
title: 2018-09-03 TIL
comments: true
category: TIL
tags:
- FaaS
- OpenFaaS
- TIL

---



# 오늘 한 일



## FaaS - workshop lab4, lab5 - 4 pmd



#### Lab 4 - Go deeper with functions



- fass-cli에서 query와 header로 function 실행
- watchdog의 작동방식(stdin/stdout으로 logging)과 이로인해 logging part 설정법
- 명령어를 사용하여 2개의 채이닝(chainning) function을 하나의 콜처럼 사용하기
- OpenFaaS API Gateway를 사용하여 2개의 채이닝(chainning) function을 하나의 콜처럼 사용하기
- Sentiment Analysis function 소개

성

#### Lab 5 - Create a Gitbot



- Sentiment Analysis function을 사용한 Gitbot 만들기
- ngrok 설정
- Github 설정 ( Webhooks )
- Gitbot을 위한 코드 작성
- Github API SDK를 이용한 Gitbot 코드 작성



### reference

1. [openfaas-workshop](https://github.com/openfaas/workshop)



## EMG Pattern Classification to Control a Hand Orthosis for Functional Grasp Assistance after Stroke



Myo armband에서 출력되는 sEMG Signal의 Hand pose prediction하여 이전 논문에서 만든 장갑을 Controlling하는 제어신호로 만들겠다는 논문



 어떠한 보조기구를 제어하는 방법론

- brain control interfaces. [4]
- bilateral control. [5]
- therapist/user driven. [6]
- **EMG control**



이러한 방법론을 통해서 제어한 보조기는

- knee. [7]
- arm. [8]
- wrist. [9]



EMG control에서는 제어하는 방법론은

- using bilateral muscle. [10]
- using bicep muscles. [10], [11]

논문에서는 **ipsilateral muscles** 방법을 선택



ipsilateral muscles을 이용하여 손동작을 강화하거나, 쥐는 동작을 하는 연구가 광범위하게 일어남 [12]

- **EMG data를 이용하여 Hand pose를 예측하는 논문들 [13], [14], [15]**



보조기 영역에서 EMG-driven 제어 논문은 다음과 같음. [16], [17], [18]. 특히 [19]에서 이러한 hand pose와 EMG signal을 동일화할 수 있다고 보여줌



의수의 각각의 finger motion을 EMG Contol에서 해결하는 논문은 [22], [23], 쥐는 모션(Grasp)은 [24], 제어 최적화는 [25, 26], 의수의 제어하는 방법론에 대한 계층은 [27]에서 확인할 수 있음



논문에서는 training 방법을 사용할 것인데, GT데이터를 이용한 bilateral 학습은 [20], 사용자 학습법은 [21]이 있으며, 저자들은 **사용자 학습법**이 조금 더 가치있다고 믿는다고 설명함



### reference

- [[4]. Think to move: a neuromagnetic brain-computer interface (BCI) system for chronic stroke](https://www.ncbi.nlm.nih.gov/pubmed/18258825)
- [[5]. Development of a Hand Motion Assist Robot for Rehabilitation Therapy by Patient Self-Motion Control](https://ieeexplore.ieee.org/document/4428432/)
- [[6]. Robot-based hand motor therapy after stroke.](https://www.ncbi.nlm.nih.gov/pubmed/18156154)
- [[7]. Real-Time EMG driven Lower Limb Actuated. Orthosis for Assistance As Needed Movement. Strategy](http://www.roboticsproceedings.org/rss09/p54.pdf)
- [[8]. Exoskeleton Technology in Rehabilitation: Towards an EMG-Based Orthosis System for Upper Limb Neuromotor Rehabilitation](https://www.hindawi.com/journals/jr/2013/610589/)
- [[9]. Surface EMG pattern recognition for real-time control of a wrist exoskeleton](https://biomedical-engineering-online.biomedcentral.com/articles/10.1186/1475-925X-9-41)
- [[10]. An EMG-Controlled Hand Exoskeleton for Natural Pinching ](https://pdfs.semanticscholar.org/b865/c1f3b6ac74a7868e6188f827d62106c3a825.pdf)
- [[11]. Comparison of control strategies for an EMG controlled orthotic exoskeleton for the hand](https://ieeexplore.ieee.org/document/1308056/)
- [[13]. An EMG-controlled exoskeleton for hand rehabilitation](https://ieeexplore.ieee.org/document/1501122/)
- [[14]. Controlling the hand and forearm movements of an orthotic arm using surface EMG signals](https://ieeexplore.ieee.org/document/7443749/)
- [[15]. Interactive rehabilitation robot for hand function training](https://ieeexplore.ieee.org/document/5209564/)
- [[16]. An intention driven hand functions task training robotic system](https://www.ncbi.nlm.nih.gov/pubmed/21097247)
- [[17]. An emg-driven exoskeleton hand robotic training device on chronic stroke subjects: task training system for stroke rehabilitation](https://ieeexplore.ieee.org/document/5975340/)
- [[18]. Use of an electromyographically driven hand orthosis for training after stroke](https://www.ncbi.nlm.nih.gov/pubmed/22275586)
- [[19]. Subjectspecific myoelectric pattern classification of functional hand movements for stroke survivors](https://www.ncbi.nlm.nih.gov/pubmed/20876030)
- [[20]. Control of upper limb prostheses: terminology and proportional myoelectric controla review](https://www.ncbi.nlm.nih.gov/pubmed/22665514)
- [[21]. A training strategy for learning pattern recognition control for myoelectric prostheses](https://www.ncbi.nlm.nih.gov/pubmed/23459166)
- [[22]. Decoding of individuated finger movements using surface emg and input optimization applying a genetic algorithm](https://www.ncbi.nlm.nih.gov/pubmed/22254630)
- [[23]. Learning EMG control of a robotic hand: towards active prostheses](https://ieeexplore.ieee.org/document/1642128/)
- [[24]. Surface EMG in advanced hand prosthetics](https://www.ncbi.nlm.nih.gov/pubmed/19015872)
- [[25]. A Heuristic Fuzzy Logic Approach to EMG Pattern Recognition for Multifunctional Prosthesis Control](https://ieeexplore.ieee.org/document/1506815/)
- [[26]. A robust, real-time control scheme for multifunction myoelectric control](https://ieeexplore.ieee.org/document/1206493/)
- [[27]. On the Shared Control of an EMG-Controlled Prosthetic Hand: Analysis of UserProsthesis Interaction](https://ieeexplore.ieee.org/document/4407739/)



## Two Minute Papers



### 1. NVIDIA's Image Restoration AI : Almost Perfect



- 기준의 De-noise Network 계열은 Clean Image를 이용하여 Noise를 넣어서 Input을 Noise Image, target을 Clean Image로 사용했음
- 이러한 Dee-noise Network는 몇가지 단점이 존재했는데, light에 대한 부분을 학습하는 것과 본질적인 train data의 문제가 있었음
- light에 대한 부분은 예를들어 창을 통해서 빛이 들어올 때, 여기에 Noise를 강하게 주어서 학습시, light에 대해서 올바르게 학습하려면 대규모의 데이터셋이 필요했던 점
- Clean Image라고 불리우는 Target Data 자체가 본질적으로 Noise가 있으며, 여러가지 도메인에서 일반적으로 De-noise를 한다던 텍스트 워터마크가 들어가있는 영상에 대해서 이를 제거하는것은 불가능했음
- 일반적으로 많은 사람들이 Noise 영상으로만 학습하는 방식(Unsupervised mehod)으로 De-noise를 학습하면 이를 불가능하다라고 생각하는게 명확한데 이를 논문 저자들이 해결함
- 해결방법은 어떠한 Noise Distribution에 대한 가정을 전제하여 Set에 대한 적합한 constraint를 적용하여 Clean Image없이 Noisy Data로만 학습시켜서 De-noise를 학습함
- 그 결과 여러가지 도메인에 공통적으로 De-noise가 학습되며(일반화) 텍스트 기반의 워터마크도 제거됨



### reference

[[1]. NVIDIA's Image Restoration AI: Almost Perfect](https://www.youtube.com/watch?v=P0fMwA3X5KI)

[[2]. Noise2Noise: Learning Image Restoration without Clean Data](https://arxiv.org/abs/1803.04189)



### 2. This Neural Network Animates Quadrupeds



- 기존의 모션캡쳐방식은 어떠한 배우를 두고 스튜디오에서 센서 데이터를 취득하는 것에서 시작했음
- 이렇게 얻은 데이터를 사용하여 엔지니어와 디자이너들은 모션캡쳐를 진행했는데, 각 모션들마다 모션 캡쳐들이 필요해 데이터량이 엄청 많이 필요했고, 명확하지 않은 데이터들은 건너뛰어서 사용해야하는 경우가 있어 부자연스러웠음. 
- 이런 과정에서 수많은 인력소모 및 시간이 투입되었고, 이를 해결하기 위해 기본적인 뉴럴넷을 통해서 학습을 진행했었음
- *일반적인 뉴럴넷 방법의 경우에는 얻은 데이터와 센서데이터를 매칭시켜서 학습해주었고, 꽤나 그럴싸한 결과가 나왔으나 자세히 들여다보면 부자연스러운 부분이 존재했음*
- 해당 논문에서 제안한 새로운 방식은 기존 뉴럴넷 방식의 부자연스러운 문제를 해결했으며 학습데이터도 1시간의 모션캡쳐 데이터로 학습이 가능함
- 중요한것은 이러한 결과가 평지에서만 실험한 것으로 확인을 하였지만 논문의 방법은 평지가 아닌 곳에서도 자연스러운 결과를 보여줌



### reference

[[1]. This Neural Network Animates Quadrupeds](https://www.youtube.com/watch?v=Mnu1DzFzRWs)

[[2]. Mode-Adaptive Neural Networks for Quadruped Motion Control](http://homepages.inf.ed.ac.uk/tkomura/dog.pdf)



### 3. Everybody Dance Now! - AI-Based Motion Transfer



- Style Transfer, pix2pix, pose detection을 이용하여 target의 pose를 source의 pose로 만들고 texture는 pix2pix와 style transfer를 이용하여 모션캡쳐를 진행



[[1]. Everybody Dance Now! - AI-Based Motion Transfer](https://www.youtube.com/watch?v=cEBgi6QYDhQ)
[[2]. Everybody Dance Now](https://arxiv.org/abs/1808.07371https://arxiv.org/abs/1808.07371)